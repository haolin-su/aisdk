# 核心层设计

## 概要
### 背景

随着AI模型的不断发展，模型的推理速度越来越快，同时，模型的规模也越来越大，导致模型的推理效率越来越低。为了提高模型的推理效率，我们需要对模型进行优化，比如模型的并行化、模型的分布式部署等。同时，为了提升模型的易用性，我们需要提供一套易用的API，让用户可以方便地调用模型进行推理。

### 需要解决的问题

- 如何提升模型的推理效率？
- 如何提升模型的易用性？
- 如何降低模型的部署难度？


### 目标

- 提升模型的推理效率
- 提升模型的易用性
- 降低模型的部署难度


### 设计思路

- 提升模型的推理效率：通过模型的并行化、分布式部署等方式提升模型的推理效率。
- 提升模型的易用性：提供一套易用的API，让用户可以方便地调用模型进行推理。
- 降低模型的部署难度：通过提供一套模型部署工具，降低模型的部署难度。


### 架构设计
![core-layer-design](https://i.imgur.com/y9y5y1L.png)



### 主要模块
- session
- infer server
- request 
- executor
- engine
- node
- model manager
- pipeline
- processor
- thread pool
- memory pool
- device manager
- device
- priority queue
- batcher

## 模块详细设计

### session
session模块负责管理与客户端的会话，包括创建、销毁、管理请求等。

### infer server
infer server模块负责接收客户端的请求，并将请求分发给executor模块。

### request
request模块负责封装客户端的请求，包括请求的类型、请求的数据、请求的元数据等。

### executor
executor模块负责执行请求，包括创建、销毁、执行请求等。

### engine
engine模块负责管理模型的生命周期，包括加载、卸载、执行模型等。

### node
node模块负责管理模型的执行节点，包括创建、销毁、执行节点等。

### model manager
model manager模块负责管理模型的生命周期，包括加载、卸载、执行模型等。

### pipeline
pipeline模块负责管理模型的执行流程，包括创建、销毁、执行模型等。

### processor
processor模块负责管理模型的执行处理器，包括创建、销毁、执行处理器等。

### thread pool
thread pool模块负责管理线程池，包括创建、销毁、执行线程池等。

### memory pool
memory pool模块负责管理内存池，包括创建、销毁、执行内存池等。

### device manager
device manager模块负责管理设备，包括创建、销毁、执行设备等。

### device
device模块负责管理设备的生命周期，包括创建、销毁、执行设备等。

### priority queue
priority queue模块负责管理请求的优先级，包括创建、销毁、执行请求等。

### batcher
batcher模块负责管理请求的批处理，包括创建、销毁、执行请求等。

## 关键结构体定义

### Request
```c++
struct Request {
    RequestType type;

};
```

## 关键接口定义

### infer_server