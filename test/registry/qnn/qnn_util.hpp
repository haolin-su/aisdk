#ifndef __QNN_UTIL_HPP__
#define __QNN_UTIL_HPP__

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <dlfcn.h>
#include <vector>
#include <unordered_map>
#include <memory>
#include <iostream>
#include <fstream>
#include <cstring>
#include <cstdlib>
#include <iterator>
#include <algorithm>

#include "QnnInterface.h"
#include "QnnContext.h"
#include "QnnGraph.h"
#include "QnnTensor.h"
#include "QnnTypes.h"
#include "System/QnnSystemInterface.h"

enum class StatusCode {
  SUCCESS,
  FAILURE,
  FAIL_LOAD_BACKEND,
  FAIL_LOAD_MODEL,
  FAIL_SYM_FUNCTION,
  FAIL_GET_INTERFACE_PROVIDERS,
  FAIL_LOAD_SYSTEM_LIB,
};

// Graph Related Function Handle Types
typedef enum ModelError {
  MODEL_NO_ERROR               = 0,
  MODEL_TENSOR_ERROR           = 1,
  MODEL_PARAMS_ERROR           = 2,
  MODEL_NODES_ERROR            = 3,
  MODEL_GRAPH_ERROR            = 4,
  MODEL_CONTEXT_ERROR          = 5,
  MODEL_GENERATION_ERROR       = 6,
  MODEL_SETUP_ERROR            = 7,
  MODEL_INVALID_ARGUMENT_ERROR = 8,
  MODEL_FILE_ERROR             = 9,
  MODEL_MEMORY_ALLOCATE_ERROR  = 10,
  // Value selected to ensure 32 bits.
  MODEL_UNKNOWN_ERROR = 0x7FFFFFFF
} ModelError_t;

// typedef struct {
//   /// Integer identifier for a tensor.
//   uint32_t id;
//   /// Tensor name.
//   const char* name;
//   /// Tensor type.
//   Qnn_TensorType_t type;
//   /// Tensor data formatting in memory (refer to definition type for info).
//   Qnn_TensorDataFormat_t dataFormat;
//   /// Tensor data type.
//   Qnn_DataType_t dataType;
//   /// Tensor quantization params.
//   Qnn_QuantizeParams_t quantizeParams;
//   /// Tensor rank.
//   uint32_t rank;
//   /// Tensor dimension array of length _rank_. For detailed behavior of dimensions field with
//   /// various APIs, refer SDK documentation. Must be NULL when rank is 0.
//   uint32_t* dimensions;
//   /// Tensor memory type.
//   Qnn_TensorMemType_t memType;
//   /// Actual data contained in the tensor.
//   union UNNAMED {
//     /// Tensor data provided by client as a pointer to raw memory (see QNN_TENSORMEMTYPE_RAW).
//     Qnn_ClientBuffer_t clientBuf;
//     /// Tensor data shared via a memory handle (see QNN_TENSORMEMTYPE_MEMHANDLE).
//     Qnn_MemHandle_t memHandle;
//   };
// } Qnn_TensorV1_t;
// typedef struct {
//   /// Unique integer identifier for a tensor, generated by the backend based on the tensor name.
//   uint32_t id;
//   /// Unique tensor name.
//   const char* name;
//   /// Tensor type.
//   Qnn_TensorType_t type;
//   /// Tensor data formatting in memory (refer to definition type for info).
//   Qnn_TensorDataFormat_t dataFormat;
//   /// Tensor data type.
//   Qnn_DataType_t dataType;
//   /// Tensor quantization params.
//   Qnn_QuantizeParams_t quantizeParams;
//   /// Tensor rank. Note that rank cannot be dynamic.
//   uint32_t rank;
//   /// Tensor dimension array of length _rank_. For detailed behavior of dimensions field with
//   /// various APIs, refer to their API documentation. Must be NULL when rank is 0. Must contain
//   /// non-zero values if non-null.
//   uint32_t* dimensions;
//   /// Tensor memory type.
//   Qnn_TensorMemType_t memType;
//   /// Actual data contained in the tensor.
//   union UNNAMED {
//     /// Tensor data provided by client as a pointer to raw memory (see QNN_TENSORMEMTYPE_RAW).
//     Qnn_ClientBuffer_t clientBuf;
//     /// Tensor data shared via a memory handle (see QNN_TENSORMEMTYPE_MEMHANDLE).
//     Qnn_MemHandle_t memHandle;
//   };
//   /// A boolean array of length _rank_ indicating if a tensor dimension is dynamic. Must be NULL
//   /// when rank is 0. Can be NULL if all dimensions are static. A true (non-zero) value indicates
//   /// the corresponding dimension is dynamic and a false (zero) value indicates the corresponding
//   /// dimension is static. Note that QNN_TENSOR_TYPE_STATIC tensors (see _type_) cannot have dynamic
//   /// dimensions. Support for this field can be queried via
//   /// QNN_PROPERTY_TENSOR_SUPPORT_DYNAMIC_DIMENSIONS. If this field is unsupported, it must be NULL.
//   uint8_t* isDynamicDimensions;
//   /// Sparse tensor parameters. Pertains only to sparse tensors (see QNN_TENSOR_DATA_FORMAT_SPARSE).
//   /// Support for this field can be queried via QNN_PROPERTY_TENSOR_SUPPORT_SPARSITY.
//   Qnn_SparseParams_t sparseParams;
//   /// Indicates whether or not a call to QnnGraph_execute[Async] produced this output tensor.
//   /// Applicable only to QNN_TENSOR_TYPE_APP_READ and QNN_TENSOR_TYPE_APP_READWRITE tensor types.
//   /// This field will be undefined if QNN_PROPERTY_GRAPH_SUPPORT_EARLY_TERMINATION is not
//   /// supported. Otherwise, this field is not used.
//   uint8_t isProduced;
// } Qnn_TensorV2_t;
// typedef struct {
//   /// Version of the QNN tensor
//   Qnn_TensorVersion_t version;
//   union UNNAMED {
//     /// Tensor version 1 (see QNN_TENSOR_VERSION_1)
//     Qnn_TensorV1_t v1;
//     /// Tensor version 2 (see QNN_TENSOR_VERSION_2)
//     Qnn_TensorV2_t v2;
//   };
// } Qnn_Tensor_t;

typedef struct GraphInfo {
  Qnn_GraphHandle_t graph;
  char *graphName;
  Qnn_Tensor_t *inputTensors;
  uint32_t numInputTensors;
  Qnn_Tensor_t *outputTensors;
  uint32_t numOutputTensors;
} GraphInfo_t;
typedef GraphInfo_t *GraphInfoPtr_t;

typedef struct GraphConfigInfo {
  char *graphName;
  const QnnGraph_Config_t **graphConfigs;
} GraphConfigInfo_t;

typedef ModelError_t (*ComposeGraphsFnHandleType_t)(
    Qnn_BackendHandle_t,
    QNN_INTERFACE_VER_TYPE,
    Qnn_ContextHandle_t,
    const GraphConfigInfo_t **,
    const uint32_t,
    GraphInfo_t ***,
    uint32_t *,
    bool,
    QnnLog_Callback_t,
    QnnLog_Level_t);

typedef ModelError_t (*FreeGraphInfoFnHandleType_t)(
    GraphInfo_t ***, uint32_t);


typedef ModelError_t (*QnnModel_composeGraphsFromDlc_t)(Qnn_BackendHandle_t backendHandle,
                                        QNN_INTERFACE_VER_TYPE interface,
                                        Qnn_ContextHandle_t contextHandle,
                                        const GraphConfigInfo_t **graphsConfigInfo,
                                        const char *dlcPath,
                                        const uint32_t numGraphsConfigInfo,
                                        GraphInfoPtr_t **graphsInfo,
                                        uint32_t *numGraphsInfo,
                                        bool debug,
                                        QnnLog_Callback_t logCallback,
                                        QnnLog_Level_t maxLogLevel);


typedef struct QnnFunctionPointers {
    ComposeGraphsFnHandleType_t composeGraphsFnHandle;
    FreeGraphInfoFnHandleType_t freeGraphInfoFnHandle;
    QnnModel_composeGraphsFromDlc_t qnnModelComposeGraphsFromDlc;
    QNN_INTERFACE_VER_TYPE qnnInterface;
    QNN_SYSTEM_INTERFACE_VER_TYPE qnnSystemInterface;
} QnnFunctionPointers;

void logStdoutCallback(const char* fmt,
                           QnnLog_Level_t level,
                           uint64_t timestamp,
                           va_list argp);

template <class T>
static inline T resolveSymbol(void* libHandle, const char* symName) {
    T ptr = (T)::dlsym(libHandle, symName);
    if (ptr == nullptr) {
        printf("Unable to access symbol [%s]. dlerror(): %s", symName, dlerror());
    }
    return ptr;
}

size_t getFileSize(std::string filePath);

inline uint32_t getQnnTensorId(const Qnn_Tensor_t& tensor) {
  // TensorCompatTest justifies no need to check version
  return tensor.v1.id;
}

inline uint32_t getQnnTensorId(const Qnn_Tensor_t* const tensor) { return getQnnTensorId(*tensor); }

inline const char* getQnnTensorName(const Qnn_Tensor_t& tensor) {
  // TensorCompatTest justifies no need to check version
  return tensor.v1.name;
}

inline const char* getQnnTensorName(const Qnn_Tensor_t* const tensor) {
  return getQnnTensorName(*tensor);
}

inline Qnn_TensorType_t getQnnTensorType(const Qnn_Tensor_t& tensor) {
  // TensorCompatTest justifies no need to check version
  return tensor.v1.type;
}

inline Qnn_TensorType_t getQnnTensorType(const Qnn_Tensor_t* const tensor) {
  return getQnnTensorType(*tensor);
}

inline Qnn_TensorDataFormat_t getQnnTensorDataFormat(const Qnn_Tensor_t& tensor) {
  // TensorCompatTest justifies no need to check version
  return tensor.v1.dataFormat;
}

inline Qnn_TensorDataFormat_t getQnnTensorDataFormat(const Qnn_Tensor_t* const tensor) {
  return getQnnTensorDataFormat(*tensor);
}

inline Qnn_DataType_t getQnnTensorDataType(const Qnn_Tensor_t& tensor) {
  // TensorCompatTest justifies no need to check version
  return tensor.v1.dataType;
}

inline Qnn_DataType_t getQnnTensorDataType(const Qnn_Tensor_t* const tensor) {
  return getQnnTensorDataType(*tensor);
}

inline Qnn_QuantizeParams_t getQnnTensorQuantParams(const Qnn_Tensor_t& tensor) {
  // TensorCompatTest justifies no need to check version
  return tensor.v1.quantizeParams;
}

inline Qnn_QuantizeParams_t getQnnTensorQuantParams(const Qnn_Tensor_t* const tensor) {
  if (tensor != nullptr) {
    return getQnnTensorQuantParams(*tensor);
  }
  return QNN_QUANTIZE_PARAMS_INIT;
}

inline uint32_t getQnnTensorRank(const Qnn_Tensor_t& tensor) {
  // TensorCompatTest justifies no need to check version
  return tensor.v1.rank;
}

inline uint32_t getQnnTensorRank(const Qnn_Tensor_t* const tensor) {
  if (tensor != nullptr) {
    return getQnnTensorRank(*tensor);
  }
  return 0u;
}

inline uint32_t* getQnnTensorDimensions(const Qnn_Tensor_t& tensor) {
  // TensorCompatTest justifies no need to check version
  return tensor.v1.dimensions;
}

inline uint32_t* getQnnTensorDimensions(const Qnn_Tensor_t* const tensor) {
  return getQnnTensorDimensions(*tensor);
}

inline uint8_t* getQnnTensorIsDynamicDimensions(const Qnn_Tensor_t& tensor) {
  if (tensor.version == QNN_TENSOR_VERSION_1) {
    return NULL;
  } else if (tensor.version == QNN_TENSOR_VERSION_2) {
    return tensor.v2.isDynamicDimensions;
  }
  return NULL;
}

inline uint8_t* getQnnTensorIsDynamicDimensions(const Qnn_Tensor_t* tensor) {
  return getQnnTensorIsDynamicDimensions(*tensor);
}

inline Qnn_SparseParams_t getQnnTensorSparseParams(const Qnn_Tensor_t& tensor) {
  if (tensor.version == QNN_TENSOR_VERSION_1) {
    return QNN_SPARSE_PARAMS_INIT;
  } else if (tensor.version == QNN_TENSOR_VERSION_2) {
    return tensor.v2.sparseParams;
  }
  return QNN_SPARSE_PARAMS_INIT;
}

inline Qnn_SparseParams_t getQnnTensorSparseParams(const Qnn_Tensor_t* tensor) {
  return getQnnTensorSparseParams(*tensor);
}

inline Qnn_TensorMemType_t getQnnTensorMemType(const Qnn_Tensor_t& tensor) {
  // TensorCompatTest justifies no need to check version
  return tensor.v1.memType;
}

inline Qnn_TensorMemType_t getQnnTensorMemType(const Qnn_Tensor_t* const tensor) {
  return getQnnTensorMemType(*tensor);
}

inline Qnn_ClientBuffer_t getQnnTensorClientBuf(const Qnn_Tensor_t& tensor) {
  // TensorCompatTest justifies no need to check version
  return tensor.v1.clientBuf;
}

inline Qnn_ClientBuffer_t getQnnTensorClientBuf(const Qnn_Tensor_t* const tensor) {
  return getQnnTensorClientBuf(*tensor);
}

inline Qnn_MemHandle_t getQnnTensorMemHandle(const Qnn_Tensor_t& tensor) {
  // TensorCompatTest justifies no need to check version
  return tensor.v1.memHandle;
}

inline Qnn_MemHandle_t getQnnTensorMemHandle(const Qnn_Tensor_t* const tensor) {
  return getQnnTensorMemHandle(*tensor);
}

inline void setQnnTensorId(Qnn_Tensor_t& tensor, const uint32_t id) {
  // TensorCompatTest justifies no need to check version
  tensor.v1.id = id;
}

inline void setQnnTensorId(Qnn_Tensor_t* const tensor, const uint32_t id) {
  setQnnTensorId(*tensor, id);
}

inline void setQnnTensorName(Qnn_Tensor_t& tensor, const char* const name) {
  // TensorCompatTest justifies no need to check version
  tensor.v1.name = name;
}

inline void setQnnTensorName(Qnn_Tensor_t* const tensor, const char* const name) {
  setQnnTensorName(*tensor, name);
}

inline void setQnnTensorType(Qnn_Tensor_t& tensor, const Qnn_TensorType_t type) {
  // TensorCompatTest justifies no need to check version
  tensor.v1.type = type;
}

inline void setQnnTensorType(Qnn_Tensor_t* const tensor, const Qnn_TensorType_t type) {
  setQnnTensorType(*tensor, type);
}

inline void setQnnTensorDataFormat(Qnn_Tensor_t& tensor, const Qnn_TensorDataFormat_t dataFormat) {
  // TensorCompatTest justifies no need to check version
  tensor.v1.dataFormat = dataFormat;
}

inline void setQnnTensorDataFormat(Qnn_Tensor_t* const tensor,
                                   const Qnn_TensorDataFormat_t format) {
  setQnnTensorDataFormat(*tensor, format);
}

inline void setQnnTensorDataType(Qnn_Tensor_t& tensor, const Qnn_DataType_t dataType) {
  // TensorCompatTest justifies no need to check version
  tensor.v1.dataType = dataType;
}

inline void setQnnTensorDataType(Qnn_Tensor_t* const tensor, const Qnn_DataType_t dataType) {
  setQnnTensorDataType(*tensor, dataType);
}

inline void setQnnTensorQuantParams(Qnn_Tensor_t& tensor,
                                    const Qnn_QuantizeParams_t quantizeParams) {
  // TensorCompatTest justifies no need to check version
  tensor.v1.quantizeParams = quantizeParams;
}

inline void setQnnTensorQuantParams(Qnn_Tensor_t* const tensor, const Qnn_QuantizeParams_t params) {
  setQnnTensorQuantParams(*tensor, params);
}

inline void setQnnTensorRank(Qnn_Tensor_t& tensor, const uint32_t rank) {
  // TensorCompatTest justifies no need to check version
  tensor.v1.rank = rank;
}

inline void setQnnTensorRank(Qnn_Tensor_t* const tensor, const uint32_t rank) {
  setQnnTensorRank(*tensor, rank);
}

inline void setQnnTensorDimensions(Qnn_Tensor_t& tensor, uint32_t* const dimensions) {
  // TensorCompatTest justifies no need to check version
  tensor.v1.dimensions = dimensions;
}

inline void setQnnTensorDimensions(Qnn_Tensor_t* const tensor, uint32_t* const dimensions) {
  setQnnTensorDimensions(*tensor, dimensions);
}

inline void setQnnTensorIsDynamicDimensions(Qnn_Tensor_t& tensor,
                                            uint8_t* const isDynamicDimensions) {
  if (tensor.version == QNN_TENSOR_VERSION_2) {
    tensor.v2.isDynamicDimensions = isDynamicDimensions;
  }
}

inline void setQnnTensorIsDynamicDimensions(Qnn_Tensor_t* tensor,
                                            uint8_t* const isDynamicDimensions) {
  setQnnTensorIsDynamicDimensions(*tensor, isDynamicDimensions);
}

inline void setQnnTensorSparseParams(Qnn_Tensor_t& tensor, const Qnn_SparseParams_t sparseParams) {
  if (tensor.version == QNN_TENSOR_VERSION_2) {
    tensor.v2.sparseParams = sparseParams;
  }
}

inline void setQnnTensorSparseParams(Qnn_Tensor_t* tensor, Qnn_SparseParams_t sparseParams) {
  setQnnTensorSparseParams(*tensor, sparseParams);
}

inline void setQnnTensorMemType(Qnn_Tensor_t& tensor, const Qnn_TensorMemType_t memType) {
  // TensorCompatTest justifies no need to check version
  tensor.v1.memType = memType;
}

inline void setQnnTensorMemType(Qnn_Tensor_t* const tensor, const Qnn_TensorMemType_t memType) {
  setQnnTensorMemType(*tensor, memType);
}

inline void setQnnTensorClientBuf(Qnn_Tensor_t& tensor, const Qnn_ClientBuffer_t clientBuf) {
  // TensorCompatTest justifies no need to check version
  tensor.v1.clientBuf = clientBuf;
}

inline void setQnnTensorClientBuf(Qnn_Tensor_t* const tensor, const Qnn_ClientBuffer_t clientBuf) {
  setQnnTensorClientBuf(*tensor, clientBuf);
}

inline void setQnnTensorMemHandle(Qnn_Tensor_t& tensor, const Qnn_MemHandle_t memHandle) {
  // TensorCompatTest justifies no need to check version
  tensor.v1.memHandle = memHandle;
}

inline void setQnnTensorMemHandle(Qnn_Tensor_t* const tensor, const Qnn_MemHandle_t handle) {
  setQnnTensorMemHandle(*tensor, handle);
}


// Accessors for QNN Tensor
#define QNN_TENSOR_GET_ID(tensor)                    getQnnTensorId(tensor)
#define QNN_TENSOR_GET_NAME(tensor)                  getQnnTensorName(tensor)
#define QNN_TENSOR_GET_TYPE(tensor)                  getQnnTensorType(tensor)
#define QNN_TENSOR_GET_DATA_FORMAT(tensor)           getQnnTensorDataFormat(tensor)
#define QNN_TENSOR_GET_DATA_TYPE(tensor)             getQnnTensorDataType(tensor)
#define QNN_TENSOR_GET_QUANT_PARAMS(tensor)          getQnnTensorQuantParams(tensor)
#define QNN_TENSOR_GET_RANK(tensor)                  getQnnTensorRank(tensor)
#define QNN_TENSOR_GET_DIMENSIONS(tensor)            getQnnTensorDimensions(tensor)
#define QNN_TENSOR_GET_IS_DYNAMIC_DIMENSIONS(tensor) getQnnTensorIsDynamicDimensions(tensor)
#define QNN_TENSOR_GET_SPARSE_PARAMS(tensor)         getQnnTensorSparseParams(tensor)
#define QNN_TENSOR_GET_MEM_TYPE(tensor)              getQnnTensorMemType(tensor)
#define QNN_TENSOR_GET_CLIENT_BUF(tensor)            getQnnTensorClientBuf(tensor)
#define QNN_TENSOR_GET_MEM_HANDLE(tensor)            getQnnTensorMemHandle(tensor)

// Modifiers for QNN Tensor
#define QNN_TENSOR_SET_ID(tensor, value)           setQnnTensorId(tensor, value)
#define QNN_TENSOR_SET_NAME(tensor, value)         setQnnTensorName(tensor, value)
#define QNN_TENSOR_SET_TYPE(tensor, value)         setQnnTensorType(tensor, value)
#define QNN_TENSOR_SET_DATA_FORMAT(tensor, value)  setQnnTensorDataFormat(tensor, value)
#define QNN_TENSOR_SET_DATA_TYPE(tensor, value)    setQnnTensorDataType(tensor, value)
#define QNN_TENSOR_SET_QUANT_PARAMS(tensor, value) setQnnTensorQuantParams(tensor, value)
#define QNN_TENSOR_SET_RANK(tensor, value)         setQnnTensorRank(tensor, value)
#define QNN_TENSOR_SET_DIMENSIONS(tensor, value)   setQnnTensorDimensions(tensor, value)
#define QNN_TENSOR_SET_IS_DYNAMIC_DIMENSIONS(tensor, value) \
  setQnnTensorIsDynamicDimensions(tensor, value)
#define QNN_TENSOR_SET_SPARSE_PARAMS(tensor, value) setQnnTensorSparseParams(tensor, value)
#define QNN_TENSOR_SET_MEM_TYPE(tensor, value)      setQnnTensorMemType(tensor, value)
#define QNN_TENSOR_SET_CLIENT_BUF(tensor, value)    setQnnTensorClientBuf(tensor, value)
#define QNN_TENSOR_SET_MEM_HANDLE(tensor, value)    setQnnTensorMemHandle(tensor, value)


int freeQnnTensor(Qnn_Tensor_t &tensor) ;

int freeQnnTensors(Qnn_Tensor_t *&tensors,
                                                              uint32_t numTensors);

int freeGraphsInfo(GraphInfoPtr_t **graphsInfo,
                                                              uint32_t numGraphs);

int memscpy(void *dst, size_t dstSize, const void *src, size_t copySize);



bool deepCopyQnnTensorInfo(Qnn_Tensor_t *dst, const Qnn_Tensor_t *src);

bool copyTensorsInfo(const Qnn_Tensor_t *tensorsInfoSrc,
                                 Qnn_Tensor_t *&tensorWrappers,
                                 uint32_t tensorsCount) ;

bool copyGraphsInfoV1(const QnnSystemContext_GraphInfoV1_t *graphInfoSrc,
                                  GraphInfo_t *graphInfoDst);

bool copyGraphsInfo(const QnnSystemContext_GraphInfo_t *graphsInput,
                                const uint32_t numGraphs,
                                GraphInfo_t **&graphsInfo);

int load_qnn_function_pointers(QnnFunctionPointers* qnnFunctionPointers, const char* qnn_backend_file, 
                               const char* qnn_model_file, const char* qnn_systefile, const char* qnn_modeldlc_file) ;


int Init(QnnFunctionPointers* qnnFunctionPointers, Qnn_LogHandle_t &logHandle, 
            Qnn_BackendHandle_t &backendHandle, Qnn_DeviceHandle_t &deviceHandle,
             Qnn_ContextHandle_t &context, QnnContext_Config_t **contextConfigs,
             Qnn_GraphHandle_t &graphHandle, 
             GraphInfo_t** &graphsInfo, uint32_t &graphsCount,
             Qnn_ProfileHandle_t &profileBackendHandle, const char* cache_model_file,
             const char* dlc_model_file, bool used_cache);

// int load_model(QnnFunctionPointers* qnnFunctionPointers, const char* cache_model_file, 
//                Qnn_BackendHandle_t backendHandle, Qnn_DeviceHandle_t deviceHandle, Qnn_ProfileHandle_t &profileBackendHandle,
//                Qnn_GraphHandle_t* graphHandle, 
//                Qnn_ContextHandle_t &context, QnnContext_Config_t **contextConfigs,
//                GraphInfo_t** &graphsInfo, uint32_t &graphsCount,
//                const char* dlc_model_file = nullptr, bool used_cache = false) ;


int ready_tensors(Qnn_Tensor_t** input_tensors, Qnn_Tensor_t** output_tensors,
                  uint32_t &inputNum, uint32_t &outputNum,
                  uint32_t &inputSize, uint32_t &outputSize,
                  Qnn_DataType_t &input_dataType, Qnn_DataType_t &output_dataType,
                  uint32_t &inputDataSize, uint32_t &outputDataSize,
                  Qnn_GraphHandle_t &graphHandle, Qnn_ContextHandle_t &context,
                  GraphInfo_t** graphsInfo, uint32_t &graphsCount);

int read_input_data(Qnn_Tensor_t* input_tensors, uint32_t inputSize, uint32_t inputDataSize, const char* input_file);

int save_output_data(Qnn_Tensor_t* output_tensors, uint32_t outputSize, uint32_t outputDataSize, const char* output_file);

#endif // __QNN_UTIL_HPP__